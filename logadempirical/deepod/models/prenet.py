# -*- coding: utf-8 -*-
"""
Weakly-supervised anomaly detection by pairwise relation prediction task
@Author: Hongzuo Xu <hongzuoxu@126.com, xuhongzuo13@nudt.edu.cn>
"""

from deepod.core.base_model import BaseDeepAD
from deepod.core.base_networks import MLPnet, LinearBlock, GRUNet, LSTMNet
import torch
import numpy as np
import gc


class PReNet(BaseDeepAD):
    def __init__(self, epochs=100, batch_size=256, lr=1e-3, data_type='ts', seq_len=100,
                 rep_dim=128, hidden_dims='100,50', act='LeakyReLU', bias=False, contamination=0.1,
                 epoch_steps=-1, prt_steps=10, device='cuda',
                 verbose=2, random_state=42):
        super(PReNet, self).__init__(
            model_name='PReNet', epochs=epochs, batch_size=batch_size, lr=lr, seq_len=seq_len,
            epoch_steps=epoch_steps, prt_steps=prt_steps, device=device,data_type=data_type, 
            verbose=verbose, random_state=random_state, contamination=contamination,
        )

        self.hidden_dims = hidden_dims
        self.rep_dim = rep_dim
        self.act = act
        self.bias = bias

        return

    def training_prepare(self, X, y):
        train_loader = PReNetLoader(X, y, batch_size=self.batch_size)
        if self.net is None:
            net = DualInputNet(
                self.n_features, 
                hidden_dims=self.hidden_dims,
                rep_dim=self.rep_dim,
                activation='ReLU',
                bias=False,
            ).to(self.device)
        else:
            net = self.net

        criterion = torch.nn.L1Loss(reduction='mean')
        return train_loader, net, criterion

    def inference_prepare(self, X):
        # test loader: list of batches
        y = self.train_label
        unlabeled_id = np.where(y == 0)[0]
        known_anom_id = np.where(y == 1)[0]

        if X.shape[0] > 100000:
            a = 10
        elif X.shape[0] > 50000:
            a = 20
        else:
            a = 30

        X = torch.from_numpy(X)
        train_data = torch.from_numpy(self.train_data)

        x2_a_lst = []
        x2_u_lst = []
        for i in range(a):
            a_idx = np.random.choice(known_anom_id, X.shape[0], replace=True)
            u_idx = np.random.choice(unlabeled_id, X.shape[0], replace=True)
            x2_a = train_data[a_idx]
            x2_u = train_data[u_idx]

            x2_a_lst.append(x2_a)
            x2_u_lst.append(x2_u)

        test_loader = []

        n_batches = int(np.ceil(len(X) / self.batch_size))
        for i in range(n_batches):
            left = i * self.batch_size
            right = min((i + 1) * self.batch_size, len(X))
            batch_x1 = X[left: right]
            batch_x_sup1 = [x2[left: right] for x2 in x2_a_lst]
            batch_x_sup2 = [x2[left: right] for x2 in x2_u_lst]
            test_loader.append([batch_x1, batch_x_sup1, batch_x_sup2])
        self.criterion.reduction = 'none'
        return test_loader

    def training_forward(self, batch_x, net, criterion):
        batch_x1, batch_x2, batch_y = batch_x
        batch_x1 = batch_x1.float().to(self.device)
        batch_x2 = batch_x2.float().to(self.device)
        batch_y = batch_y.float().to(self.device)
        pred = net(batch_x1, batch_x2).flatten()

        loss = criterion(pred, batch_y)
        return loss

    def inference_forward(self, batch_x, net, criterion):
        batch_x1, batch_x_sup1_lst, batch_x_sup2_lst = batch_x

        batch_x1 = batch_x1.float().to(self.device)
        pred_s = []
        for batch_x2 in batch_x_sup1_lst:
            batch_x2 = batch_x2.float().to(self.device)
            pred = net(batch_x1, batch_x2).flatten()
            pred_s.append(pred)
        for batch_x2 in batch_x_sup2_lst:
            batch_x2 = batch_x2.float().to(self.device)
            pred = net(batch_x1, batch_x2).flatten()
            pred_s.append(pred)

        pred_s = torch.stack(pred_s)
        s = torch.mean(pred_s, dim=0)

        batch_z = batch_x1  # for consistency
        return batch_z, s


class DualInputNet(torch.nn.Module):
    def __init__(self, n_features, hidden_dims='100,50', rep_dim=64,
                 activation='ReLU', bias=False):
        super(DualInputNet, self).__init__()

        self.enc_net = LSTMNet(n_features=n_features,
                              n_hidden=hidden_dims,
                              n_output=rep_dim,
                              activation=activation,
                              bias=bias)
        self.out_layer = LinearBlock(
            in_channels=2 * rep_dim,
            out_channels=1,
            activation=None,
            bias=False
        )
        return

    def forward(self, x1, x2):
        x1 = self.enc_net(x1)
        x2 = self.enc_net(x2)
        pred = self.out_layer(torch.cat([x1, x2], dim=1))
        return pred


class PReNetLoader:
    def __init__(self, X, y, batch_size, steps_per_epoch=None):
        assert len(X) == len(y)
        print('X:', X.shape)
        self.X = X
        self.y = y
        self.batch_size = min(batch_size, len(X))
        self.seq_len = X.shape[1]

        self.unlabeled_id = np.where(y == 0)[0]
        self.known_anom_id = np.where(y == 1)[0]

        self.dim = self.X.shape[2]

        self.counter = 0

        self.steps_per_epoch = steps_per_epoch if steps_per_epoch is not None \
            else int(len(X) / self.batch_size)

        return

    def __iter__(self):
        self.counter = 0
        return self

    def __next__(self):
        self.counter += 1
        x1, x2, y = self.batch_generation()
        x1, x2, y = torch.from_numpy(x1), torch.from_numpy(x2), torch.from_numpy(y)

        if self.counter > self.steps_per_epoch:
            raise StopIteration

        return x1, x2, y

    def batch_generation(self):
        batch_x1 = np.empty([self.batch_size, self.seq_len, self.dim])
        batch_x2 = np.empty([self.batch_size, self.seq_len, self.dim])
        batch_y = np.empty(self.batch_size)
        for i in range(self.batch_size):
            if i % 4 == 0 or i % 4 == 1:
                sid = np.random.choice(self.unlabeled_id, 2, replace=False)
                batch_x1[i] = self.X[sid[0]]
                batch_x2[i] = self.X[sid[1]]
                batch_y[i] = 0

            elif i % 4 == 2:
                sid1 = np.random.choice(self.unlabeled_id, 1)
                sid2 = np.random.choice(self.known_anom_id, 1)
                batch_x1[i] = self.X[sid1[0]]
                batch_x2[i] = self.X[sid2[0]]
                batch_y[i] = 4

            else:
                sid = np.random.choice(self.known_anom_id, 2, replace=False)
                batch_x1[i] = self.X[sid[0]]
                batch_x2[i] = self.X[sid[1]]
                batch_y[i] = 8

        return batch_x1, batch_x2, batch_y
